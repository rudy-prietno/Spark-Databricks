{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a921948-a01b-48f5-9bb2-7f8a3e7a9dc4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Preparation Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "040d37a2-089a-431d-aaa7-91015a4c3e90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Move the file to the correct path\n",
    "dbutils.fs.cp(\"dbfs:/FileStore/tables/coreFunction.py\", \"file:/databricks/driver/coreFunction.py\")\n",
    "\n",
    "# Add the directory to the system path\n",
    "import sys\n",
    "sys.path.append(\"/databricks/driver/\")\n",
    "\n",
    "# Now, import the coreFunction module\n",
    "import coreFunction\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b59a5df-0e4f-484a-8cfd-733f8269954b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Extract from Silver - Transform in Dataframe - Load to Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "294e1200-9a7a-415e-92b3-7cfbdec2e7b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold_data.transactions_datamart is a Delta table.\nPrimary key AccountNo is unique. Starting merge into Delta table.\nNumber of rows updated: 10\nNumber of rows inserted: 0\n"
     ]
    }
   ],
   "source": [
    "silver_df = spark.read.format(\"delta\").table(\"silver_data.transactions_clean\")\n",
    "\n",
    "# Transform: Calculate TotalDeposits, TotalWithdrawals, NetBalance, and LastTransactionDate\n",
    "transformed_df = silver_df.groupBy(\"AccountNo\").agg(\n",
    "    F.sum(\"DepositAMT\").alias(\"TotalDeposits\"),\n",
    "    F.sum(\"WithdrawalAMT\").alias(\"TotalWithdrawals\"),\n",
    "    F.last(\"BalanceAMT\").alias(\"NetBalance\"),\n",
    "    F.max(\"Date\").alias(\"LastTransactionDate\")\n",
    ")\n",
    "\n",
    "coreFunction.DataIngestion.DeltaTables(\n",
    "    tableName=\"gold_data.transactions_datamart\", \n",
    "    dataFrameSource=transformed_df, \n",
    "    primaryKey=\"AccountNo\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f0dffc5-fed9-4b58-8d85-2f19dc337db0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Data Quality: Silver vs Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01c22852-4d7d-490a-a2e6-8615ff1aed49",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15efce4746a94d13926094b5efa6fd2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8c55a860874524ac6cb12782e01277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 'quality_data.quality_monitoring' is an existing Delta table.\n[INFO] Created DataFrame for DQ results: {'ID': '14988c846caf2ab0e6bc67bc20d7e9929fe901dd42d0c111a05e0b9774b9619d', 'Updated_Date': '2024-09-11', 'Updated_Timestamp': '2024-09-11 19:15:58', 'Type': 'datamart', 'Process': 'silver_to_gold', 'Type_File_Sources': 'delta', 'File_Sources': 'dbfs:/user/hive/warehouse/gold_data.db/transactions_datamart', 'Table_Name': 'transactions_datamart', 'Status_Observation': 'PASS', 'Source_Observation': 10, 'Destination_Observation': 10, 'Difference_Observation': 0, 'Status_Rows': 'PASS', 'Source_Rows': 10, 'Destination_Rows': 10, 'Difference_Rows': 0}.\n[INFO] Successfully merged DQ results into the Delta table.\nNumber of rows updated: 1\nNumber of rows inserted: 0\n"
     ]
    }
   ],
   "source": [
    "# sources\n",
    "silver_df_profile = spark.read.format(\"delta\").table(\"silver_data.transactions_clean\")\n",
    "\n",
    "transformed_df = silver_df_profile.groupBy(\"AccountNo\").agg(\n",
    "    F.sum(\"DepositAMT\").alias(\"TotalDeposits\"),\n",
    "    F.sum(\"WithdrawalAMT\").alias(\"TotalWithdrawals\"),\n",
    "    F.last(\"BalanceAMT\").alias(\"NetBalance\"),\n",
    "    F.max(\"Date\").alias(\"LastTransactionDate\")\n",
    ")\n",
    "\n",
    "silver_df = transformed_df.select(\"AccountNo\")\n",
    "\n",
    "silver_df_profile = silver_df.toPandas()\n",
    "\n",
    "profiler_silver = coreFunction.DataProfiling(titleProfile=\"Profiling Report Silver: Gold\")\n",
    "profiler_sources =profiler_silver.profile(silver_df_profile)\n",
    "\n",
    "source_observation= profiler_sources.description_set.table['n']\n",
    "source_rows= profiler_sources.description_set.variables['AccountNo']['n_distinct']\n",
    "\n",
    "# destination\n",
    "gold_df_profile = spark.read.format(\"delta\").table(\"gold_data.transactions_datamart\").select(\"AccountNo\")\n",
    "\n",
    "gold_df_profile = gold_df_profile.toPandas()\n",
    "\n",
    "profiler_gold = coreFunction.DataProfiling(titleProfile=\"Profiling Report Gold\")\n",
    "profiler_destination =profiler_gold.profile(gold_df_profile)\n",
    "\n",
    "destination_observation= profiler_destination.description_set.table['n']\n",
    "destination_rows= profiler_destination.description_set.variables['AccountNo']['n_distinct']\n",
    "\n",
    "\n",
    "coreFunction.dataQuality.generate_data_quality_report(\n",
    "            tableDQ= 'quality_data.quality_monitoring',\n",
    "            source_observation= source_observation, \n",
    "            destination_observation= destination_observation, \n",
    "            source_rows= source_rows, \n",
    "            destination_rows= destination_rows, \n",
    "            table_name= 'transactions_datamart',\n",
    "            process= 'silver_to_gold',\n",
    "            etlType= 'datamart',\n",
    "            dataFormat= 'delta',\n",
    "            file_path= 'dbfs:/user/hive/warehouse/gold_data.db/transactions_datamart'\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "mini-apps [datamart]",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
